# PRD: Comprehensive Transformation Research Expansion

**Version**: 1.2.2
**Date**: 2026-01-03
**Status**: Incremental PRD (appends to existing tasks)

---

## 1. Overview

This PRD expands the transformation search methodology based on critical observations from Phase 4 work. It establishes:

1. **Documentation Framework**: Structured logging system for all research experiments
2. **Expanded Methodology**: Comprehensive exploration of transformation approaches
3. **Rigorous Validation**: Multiple loss functions, statistical analysis, and cross-validation

**Core Research Question**: Find transformations (linear or non-linear) that rotate, translate, and deform screen color polyhedra to conform to surface color reference polyhedra in Munsell space.

---

## 2. Phase 5.0: Research Documentation Framework

**Priority**: FIRST - Must be implemented before any other research tasks.

### 2.1 Experiment Registry System

Create a structured system for tracking all experiments with:

#### 2.1.1 Experiment Registry File
Location: `datasets/transformation_analysis/experiment_registry.json`

```json
{
  "experiments": [
    {
      "id": "EXP-001",
      "name": "Translation+Scaling Munsell Domain",
      "date": "2026-01-03T14:25:00Z",
      "status": "completed",
      "method": "translation_scaling",
      "domain": "munsell_cartesian",
      "loss_function": "combined_0.4_0.3_0.3",
      "parameters": {
        "weights": {"centroid": 0.4, "volume": 0.3, "shape": 0.3}
      },
      "results": {
        "mean_loss": 0.0535,
        "std_loss": 0.0123,
        "families_analyzed": 21
      },
      "artifacts": [
        "datasets/transformation_analysis/linear_comparison.json"
      ],
      "observations": "Best performing method so far",
      "tags": ["baseline", "linear", "munsell"]
    }
  ]
}
```

#### 2.1.2 Experiment Logging Script
Location: `scripts/experiment_logger.py`

Functions:
- `register_experiment(name, method, domain, ...)` → Returns experiment ID
- `log_result(exp_id, results_dict)`
- `log_observation(exp_id, text)`
- `search_experiments(query)` → Full-text search across observations
- `compare_experiments(exp_ids)` → Side-by-side comparison
- `export_summary(format='markdown'|'csv'|'html')`

#### 2.1.3 Observation Log
Location: `datasets/transformation_analysis/research_observations.md`

Structure:
```markdown
# Research Observations Log

## 2026-01-03

### Domain Comparison Findings (EXP-001 to EXP-003)
- Munsell Cartesian domain is 27x better than RGB, 30x better than CIELAB
- Approximate color space conversions introduce prohibitive errors
- **Key insight**: Optimization must happen in target space

### Challenges Encountered
- PyTorch not compatible with Python 3.13
- Polynomial methods failed silently on some families

### Open Questions
- Does dV in RGB map to same perceptual volume everywhere in Munsell?
- Is convex hull volume dependent on sample count?
```

### 2.2 Standard Experiment Output Format

Every experiment must produce:

1. **JSON results file**: Machine-readable with all numerical results
2. **Markdown report**: Human-readable summary with key findings
3. **Per-family breakdown**: Individual family losses/metrics
4. **Visualization** (when applicable): Plots saved as PNG

### 2.3 Searchability Requirements

- Full-text search across all observations and reports
- Filter by: method, domain, loss function, date range, tags
- Compare any set of experiments side-by-side
- Export filtered results to CSV/HTML

### 2.4 Deliverables

- [ ] `scripts/experiment_logger.py` - Experiment registration and logging
- [ ] `scripts/search_experiments.py` - Search and comparison tools
- [ ] `datasets/transformation_analysis/experiment_registry.json` - Registry file
- [ ] `datasets/transformation_analysis/research_observations.md` - Observation log
- [ ] Migrate existing Phase 4 results into new registry format

---

## 3. Phase 5.1: Loss Function Analysis

### 3.1 Separate Component Optimization

Current approach uses combined loss. We need to understand each component independently:

#### 3.1.1 Single-Component Optimizations
For each loss component, optimize independently:

| Experiment | Objective | Description |
|------------|-----------|-------------|
| L_centroid only | min ||c_screen - c_surface|| | Centroid alignment |
| L_volume only | min |V_screen/V_surface - 1| | Volume matching |
| L_shape only | min Hausdorff(S, T) | Shape alignment |

#### 3.1.2 Pairwise Optimizations
Test component pairs to understand trade-offs:

- L_centroid + L_volume
- L_centroid + L_shape
- L_volume + L_shape

#### 3.1.3 Pareto Analysis
- Generate Pareto frontier for each component pair
- Identify optimal weight combinations
- Document trade-off relationships

### 3.2 Sum vs Mean Loss

Current: mean loss across families (may hide outliers)

Test alternatives:
- **Sum loss**: Penalizes families with high error
- **Weighted mean**: Weight by family importance or sample count
- **Worst-case (minimax)**: Minimize maximum per-family loss
- **Trimmed mean**: Exclude top/bottom 5% outliers

### 3.3 Alternative Loss Functions

Explore additional metrics:

| Metric | Description | Advantage |
|--------|-------------|-----------|
| Chamfer distance | Average nearest-neighbor distance | Symmetric, differentiable |
| Earth Mover's Distance | Optimal transport | Respects point distributions |
| Spectral loss | Eigenvalue comparison | Captures global shape |
| IoU (Jaccard) | Volume intersection/union | Interpretable overlap |

### 3.4 Deliverables

- [ ] `scripts/loss_component_analysis.py` - Separate optimizations
- [ ] `scripts/pareto_analysis.py` - Multi-objective analysis
- [ ] `scripts/alternative_losses.py` - New loss implementations
- [ ] `datasets/transformation_analysis/loss_analysis_report.md`

---

## 4. Phase 5.2: Volume and Geometry Analysis

### 4.1 Jacobian Non-Uniformity Study

**Question**: Does dV in RGB map to same volume in Munsell everywhere?

#### 4.1.1 Jacobian Computation
For the RGB↔Munsell mapping f(x):
- Compute J = df/dx at grid of points across color space
- Calculate |det(J)| at each point (local volume distortion)
- Visualize distortion map

#### 4.1.2 Position-Dependent Volume Ratio
For small perturbation dV_RGB:
- dV_Munsell = |det(J(x))| × dV_RGB
- This ratio varies with position x

#### 4.1.3 Implications for Transformation
- If Jacobian varies significantly, volume matching in RGB is problematic
- May need position-dependent scaling corrections

### 4.2 Sample Size vs Volume

**Question**: Is convex hull volume dependent on sample count?

#### 4.2.1 Bootstrap Analysis
For each family:
- Subsample N points (N = 10, 20, 50, 100, ...)
- Compute convex hull volume
- Repeat 100 times
- Plot volume vs N with confidence intervals

#### 4.2.2 Asymptotic Behavior
- Determine N_min where volume stabilizes (e.g., within 5% of true)
- Flag families with insufficient samples

#### 4.2.3 Volume Normalization
Consider alternative metrics:
- Volume per sample point
- Normalized by bounding box
- Alpha-shape volume (less sensitive to outliers)

### 4.3 Deliverables

- [ ] `scripts/jacobian_analysis.py` - Volume distortion study
- [ ] `scripts/sample_size_analysis.py` - Bootstrap study
- [ ] `datasets/transformation_analysis/jacobian_map.json`
- [ ] `datasets/transformation_analysis/volume_stability_report.md`

---

## 5. Phase 5.3: Procrustes and Shape-Statistical Methods

### 5.1 Procrustes Variants

#### 5.1.1 Orthogonal Procrustes
- Find optimal rotation R: min ||RX - Y||_F
- No scaling, no shearing
- Preserves shape, only rotates

#### 5.1.2 Generalized Procrustes Analysis (GPA)
- Align N shapes simultaneously
- Find consensus shape
- Use for comparing multiple families together

#### 5.1.3 Procrustes with Scaling
- Find optimal R, s: min ||s×RX - Y||_F
- Allows uniform scaling

#### 5.1.4 Affine Procrustes
- Find optimal A: min ||AX - Y||_F
- General linear transformation
- Already implemented, compare with constrained variants

### 5.2 Active Shape Models (ASM)

Statistical model of shape variation:

1. **Training**: Learn mean shape + principal modes of variation
2. **Fitting**: Find transformation + mode weights to match target
3. **Constraint**: Only allow statistically plausible deformations

#### 5.2.1 Implementation
- Compute mean polyhedron across all families
- PCA on residual shapes
- Keep top K modes explaining 95% variance
- Transformation = rigid + K mode weights

### 5.3 Point Distribution Models (PDM)

Related to ASM but focused on point clouds:

1. **Correspondence**: Establish vertex correspondence between polyhedra
2. **Statistics**: Model point position distributions
3. **Transformation**: Constrained by learned distributions

### 5.4 Deliverables

- [ ] `scripts/procrustes_methods.py` - Procrustes implementations
- [ ] `scripts/active_shape_model.py` - ASM implementation
- [ ] `scripts/point_distribution_model.py` - PDM implementation
- [ ] `datasets/transformation_analysis/shape_model_analysis.md`

---

## 6. Phase 5.4: Advanced Deformation Methods

### 6.1 Diffeomorphometric Methods

Smooth, invertible deformations that preserve topology:

#### 6.1.1 Large Deformation Diffeomorphic Metric Mapping (LDDMM)
- Find smooth velocity field that transforms source to target
- Mathematically rigorous (geodesics in shape space)
- Computationally expensive but theoretically sound

#### 6.1.2 Thin-Plate Splines (TPS)
- Already implemented, but needs refinement
- Add regularization to prevent overfitting
- Control point selection strategy

#### 6.1.3 Free-Form Deformation (FFD)
- Control lattice with B-spline interpolation
- Hierarchical (coarse-to-fine)
- Good for local adjustments

### 6.2 Radial Basis Function (RBF) Enhancements

Current implementation may need:
- Cross-validation for kernel bandwidth
- Multiple kernel comparison (Gaussian, multiquadric, TPS)
- Regularization tuning

### 6.3 Deep Learning Deformations

If PyTorch becomes available:

#### 6.3.1 PointNet-style Architectures
- Direct point cloud processing
- Permutation invariant
- Learn global features

#### 6.3.2 Spatial Transformer Networks
- Learn transformation parameters
- End-to-end trainable
- Can compose multiple transformations

#### 6.3.3 Neural Implicit Representations
- Represent shapes as level sets
- Continuous representation
- Smooth deformations

### 6.4 Deliverables

- [ ] `scripts/diffeomorphic_methods.py` - LDDMM, enhanced TPS
- [ ] `scripts/ffd_transform.py` - Free-form deformation
- [ ] `scripts/rbf_optimization.py` - RBF with cross-validation
- [ ] `datasets/transformation_analysis/deformation_comparison.md`

---

## 7. Phase 5.5: Comprehensive Validation

### 7.1 Cross-Validation Protocol

For all methods:
1. Leave-one-family-out cross-validation
2. Bootstrap validation with confidence intervals
3. Train/test split (stratified by family size)

### 7.2 Statistical Significance Testing

- Paired t-tests between methods
- Wilcoxon signed-rank tests (non-parametric)
- Multiple comparison correction (Bonferroni, FDR)

### 7.3 Generalization Assessment

- Test on held-out families
- Apply screen→surface transform to new data
- Measure extrapolation error

### 7.4 Deliverables

- [ ] `scripts/cross_validation.py` - CV framework
- [ ] `scripts/statistical_tests.py` - Significance testing
- [ ] `datasets/transformation_analysis/validation_report.md`

---

## 8. Research Principles

### 8.1 Compute Time Philosophy

Per user guidance: **"We need to be open to spend more compute time into trying diverse approaches."**

- Don't prematurely optimize for speed
- Run thorough experiments even if slow
- Document compute requirements for reproducibility
- Use checkpointing for long-running experiments

### 8.2 Documentation Discipline

- Log every experiment immediately after running
- Note failures and negative results
- Record observations even if seemingly trivial
- Make all results searchable

### 8.3 Incremental Progress

- Each experiment builds on previous findings
- Compare new methods against established baselines
- Maintain running "best" configuration

---

## 9. Success Criteria

### Documentation Framework Success
- [ ] All Phase 4 experiments migrated to registry
- [ ] Full-text search operational
- [ ] Side-by-side comparison working
- [ ] At least 10 experiments documented with detailed observations

### Methodology Expansion Success
- [ ] At least 5 Procrustes/shape-statistical methods tested
- [ ] At least 3 advanced deformation methods tested
- [ ] All methods compared on same validation protocol
- [ ] Pareto analysis complete for loss trade-offs

### Validation Success
- [ ] Cross-validation complete for top 3 methods
- [ ] Statistical significance established
- [ ] Generalization error measured
- [ ] Final method recommendation with confidence interval

---

## 10. Dependencies

```
Phase 5.0: Documentation Framework
    ↓ (must complete first)
Phase 5.1: Loss Function Analysis ←→ Phase 5.2: Volume/Geometry Analysis
    ↓                                     ↓
Phase 5.3: Procrustes/ASM/PDM ←→ Phase 5.4: Advanced Deformations
    ↓                                     ↓
    └──────────────→ Phase 5.5: Comprehensive Validation
```

---

## 11. References

### Shape Analysis
- Dryden, I.L. & Mardia, K.V. (2016). Statistical Shape Analysis
- Bookstein, F.L. (1997). Landmark methods for forms without landmarks

### Procrustes Analysis
- Gower, J.C. (1975). Generalized Procrustes Analysis
- Schönemann, P.H. (1966). A generalized solution of the orthogonal Procrustes problem

### Diffeomorphometry
- Beg, M.F. et al. (2005). Computing Large Deformation Metric Mappings via Geodesic Flows
- Younes, L. (2010). Shapes and Diffeomorphisms

### Active Shape Models
- Cootes, T.F. et al. (1995). Active Shape Models
- Heimann, T. & Meinzer, H.P. (2009). Statistical shape models for 3D medical image segmentation

### Color Science
- Fairchild, M.D. (2013). Color Appearance Models
- Centore, P. (2020). Beige, aqua, fuchsia, etc.: Definitions for some non-basic surface colour names

---

## 12. Estimated Effort

| Phase | Description | Experiments | Compute |
|-------|-------------|-------------|---------|
| 5.0 | Documentation Framework | - | Light |
| 5.1 | Loss Function Analysis | ~20 | Medium |
| 5.2 | Volume/Geometry Analysis | ~10 | Medium |
| 5.3 | Shape-Statistical Methods | ~15 | Medium |
| 5.4 | Advanced Deformations | ~10 | Heavy |
| 5.5 | Comprehensive Validation | ~5 | Heavy |

**Total**: ~60 experiments across all phases
